{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "immune-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.20.1)\n",
      "Requirement already satisfied: bs4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from beautifulsoup4->bs4) (2.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (1.20.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: datetime in c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.3)\n",
      "Requirement already satisfied: zope.interface in c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from datetime) (5.2.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from datetime) (2021.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from zope.interface->datetime) (49.2.1)\n",
      "Collecting selenium\n",
      "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from selenium) (1.26.3)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n"
     ]
    }
   ],
   "source": [
    "#installing packages in JupyterLab temporarily\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install bs4\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install datetime\n",
    "!{sys.executable} -m pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-barcelona",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "collective-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from selenium import webdriver\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import getpass\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-football",
   "metadata": {},
   "source": [
    "**All pages with urls scraping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "greek-expression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max site number: 500\n",
      "loop:   0\n",
      "loop:   1\n",
      "loop:   2\n"
     ]
    }
   ],
   "source": [
    "############################################################################\n",
    "# Downloading offers' urls and titles from the website controlled by Selenium\n",
    "url = 'https://www.otomoto.pl/osobowe/'\n",
    "\n",
    "options = webdriver.firefox.options.Options()\n",
    "options.headless = False\n",
    "\n",
    "driver = webdriver.Firefox(executable_path=r'C:\\Users\\Admin\\Downloads\\geckodriver-v0.29.0-win64\\geckodriver.exe')\n",
    "driver.get(url)\n",
    "# create BS object from the page source\n",
    "bs = BS(driver.page_source, 'html.parser')\n",
    "\n",
    "#### click accept COOKIEs button\n",
    "# waiting a few seconds to be sure that page will be fully loaded\n",
    "time.sleep(4)\n",
    "button = driver.find_element_by_xpath('//*[@id=\"onetrust-accept-btn-handler\"]').click()\n",
    "\n",
    "# Extracting number of pages with offers list to iterate\n",
    "maxSites = bs.find_all('span', {'class':'page'})[-1].text\n",
    "print(\"Max site number: \" + maxSites)\n",
    "\n",
    "maxSites = 3 #zmienione do testowania\n",
    "\n",
    "# All offers' titles and urls scraping\n",
    "url_list = []\n",
    "title_list = []\n",
    "\n",
    "for i in range(int(maxSites)):\n",
    "    if(i > 0):\n",
    "        button = driver.find_element_by_xpath('//span[@class=\"icon-arrow_right\"]').click()\n",
    "\n",
    "    time.sleep(5)\n",
    "    bs = BS(driver.page_source, 'html.parser')\n",
    "\n",
    "    titles = bs.find_all('a', {'class':'offer-title__link'}) \n",
    "\n",
    "    links = [title['href'] for title in titles]\n",
    "    \n",
    "    titles_text = [title.text.strip() for title in titles]\n",
    " \n",
    "    for link in links:\n",
    "        url_list.append(link)\n",
    "    for title in titles_text:\n",
    "        title_list.append(title)\n",
    "        \n",
    "    print('loop:  ', i)\n",
    "    \n",
    "# Close browser:\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "affiliated-gardening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hyundai i20 1.25', 'Peugeot 308 SW', 'Peugeot 3008', 'Peugeot 508 2.0', 'Opel Astra 2.0', 'Volkswagen Golf GTD', 'Fiat 500X 1.4', 'Audi A4 Avant', 'Peugeot 208 1.2', 'Škoda Superb 1.4', 'Škoda Fabia 1.0', 'Škoda Octavia 2.0', 'Renault Captur', 'Kia Sportage 1.6', 'Audi A4 35', 'Volkswagen Polo 1.4', 'Seat Mii', 'Renault Espace', 'Porsche Macan S', 'Audi A7', 'Audi A1', 'Audi A6', 'Audi A5 2.0', 'Audi A8', 'Lexus NX 300h', 'Audi A4', 'Audi A5', 'Audi A4', 'Volkswagen Golf']\n",
      "#############\n",
      "https://www.otomoto.pl/oferta/hyundai-i20-model-2015-klima-tempomat-ledy-100-oryg-przebieg-86tys-ID6DFqDw.html#7ce9f71ee3\n"
     ]
    }
   ],
   "source": [
    "print(title_list[1:30])\n",
    "print(\"#############\")\n",
    "print(url_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "significant-arthur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Documents\\Repos\\MotoScraper\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.chdir(r'C:\\Users\\Admin\\Documents\\Repos\\MotoScraper')\n",
    "# cwd = os.getcwd()\n",
    "# print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fifth-domain",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-3b6a6d728411>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtitles_encoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"windows-1252\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtitle_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitles_encoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-145-3b6a6d728411>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtitles_encoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"windows-1252\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtitle_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitles_encoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "titles_encoded = [title.decode(\"utf-8\").encode(\"windows-1252\").decode(\"utf-8\") for title in title_list]\n",
    "print(titles_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "preliminary-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save urls to df\n",
    "urls_df = pd.DataFrame({'offer_title': title_list, 'link': url_list})\n",
    "urls_df.to_csv('urls.csv', index=False, encoding=\"Windows-1252\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "widespread-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "headerOne = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "req = Request(site, headers=headerOne)\n",
    "\n",
    "html = urlopen(req)\n",
    "bs = BS(html.read(), 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-confirmation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
